glm.fit=glm(Direction~Lag1+Lag2,data=Weekly[-i, ],family ="binomial")
pred.up=predict.glm(glm.fit, Weekly[i, ], type = "response") > 0.5
true.up=Weekly[i, ]$Direction == "Up"
if (pred.up != true.up)
error[i]=1
}
errors=c(1:dim(Weekly)[1])
for (i in 1:dim(Weekly)[1]) {
glm.fit=glm(Direction~Lag1+Lag2,data=Weekly[-i, ],family ="binomial")
pred.up=predict.glm(glm.fit, Weekly[i, ], type = "response") > 0.5
true.up=Weekly[i, ]$Direction == "Up"
if (pred.up != true.up)
errors[i]=1
}
#part e
mean(errors)
mean(error)
errors=integer(dim(Weekly)[1])
for (i in 1:dim(Weekly)[1]) {
glm.fit=glm(Direction~Lag1+Lag2,data=Weekly[-i, ],family ="binomial")
pred.up=predict.glm(glm.fit, Weekly[i, ], type = "response") > 0.5
true.up=Weekly[i, ]$Direction == "Up"
if (pred.up != true.up)
errors[i]=1
}
mean(errors)
c(1:10)
1:10
x=c(1:100000)
plot(x, 1-(1-1/x)^x)
dim(Boston)[1]
attach(Boston)
m=mean(medv)
library(MASS)
attach(Boston)
m=mean(medv)
m
size = dim(Boston)[1]
std_err=sd(medv)/sqrt(size)
std_err
boot.fn <- function(data, index) {
m=mean(data[index])
return (m)
}
boot(medv, boot.fn, 1000)
t.test(medv)
median(medv)
boot.fn <- function(data, index) {
mu <- median(data[index])
return (mu)
}
boot(medv, boot.fn, 1000)
boot.fn=function(data, index) {
mu=median(data[index])
return (mu)
}
boot(medv, boot.fn, 1000)
quantile(medv, c(0.1))
boot.fn=function(data, index) {
mu=quantile(data[index], c(0.1))
return (mu)
}
boot(medv, boot.fn, 1000)
clear
rm(list=ls())
?Hitters
glmnet()
library(glmnet)
library(MASS)
?Hitters
install.packages("glmnet")
library(glmnet)
?Hitters
load(ISLR)
?Auto
library(MASS)
?Hitters
library(ISLR)
?Hitters
attach(Hitters)
Salary
Hitters$Salary
x=model.matrix(Salary~.,Hitters)[,-1]
y=Salary
library(glmnet)
grid=10^seq(10,-2,length=100)
ridge.mod=glmnet(x,y,alpha=0,lambda=grid)
View(x)
view(y)
View(y)
y=Hitters$Salary
View(y)
is.na(y)
mean(y)
y=na.rm(y)
y=na.omit(y)
View(y)
library(glmnet)
grid=10^seq(10,-2,length=100)
ridge.mod=glmnet(x,y,alpha=0,lambda=grid)
dim(coef(ridge.mod))
ridge.mod$lambda[50]
coef(ridge.mod)[,50]
ridge.mod$lambda[60]
coef(ridge.mod)[,60]
predict(ridge.mod,s=50,type="coefficients")[1:20,]
set.seed(1)
train=sample(1:nrow(x),nrow(x)/2)
test=(-train)
y.test=y[test]
ridge.mod=glmnet(x[train,],y[train],alpha=0,lambda=grid,thresh=1e-12)
ridge.pred=predict(ridge.mod,s=4,newx=x[test,])
mean((ridge.pred-y.test)^2)
mean((mean(y[train])-y.test)^2)
ridge.pred=predict(ridge.mod,s=1e10,newx=x[test,])
mean((ridge.pred-y.test)^2)
ridge.pred=predict(ridge.mod,s=0,newx=x[test,],exact = T)
ridge.pred=predict(ridge.mod,s=0,newx=x[test,],exact=T)
ridge.pred=predict (ridge.mod ,s=0, newx=x[test ,], exact=T)
ridge.pred=predict (ridge.mod ,s=0, newx=x[test ,], exact=T)
ridge.pred=predict (ridge.mod ,s=0, newx=x[test ,], exact=TRUE)
?Toy
X = matrix(c(3, 4, 2, 2, 4, 4, 1, 4, 2, 1, 4, 3, 4, 1),nrow = 7, byrow = T)
y = c(1, 1, 1, 1, 0, 0, 0)
plot(X, col = c(rep("red", 4), rep("blue", 3)), pch = c(rep(16, 4), rep(17, 3)),
xlim = c(0, 5), ylim = c(0, 5))
plot(X, col = c(rep("red", 4), rep("blue", 3)), pch = c(rep(16, 4), rep(17, 3)),
xlim = c(0, 5), ylim = c(0, 5))
abline(1, -0.5)
abline(1,-.5)
abline(1,.5)
abline(1,-(0.5)
)
dev.off()
plot(X, col = c(rep("red", 4), rep("blue", 3)),
pch = c(rep(16, 4), rep(17, 3)),
xlim = c(0, 5), ylim = c(0, 5))
slope = 1
intercept = - 0.5
abline(intercept, slope)
X = matrix(c(3, 4, 2, 2, 4, 4, 1, 4, 2, 1, 4, 3, 4, 1),nrow = 7, byrow = T)
y = c(1, 1, 1, 1, 0, 0, 0)
plot(X, col = c(rep("red", 4), rep("blue", 4)), pch = c(rep(16, 4), rep(17, 3)),
xlim = c(0, 5), ylim = c(0, 5))
?plot()
X = matrix(c(3, 4, 2, 2, 4, 4, 1, 4, 2, 1, 4, 3, 4, 1),nrow = 7, byrow = T)
y = c(1, 1, 1, 1, 0, 0, 0)
plot(X, col = c(rep("red", 4), rep("blue", 4)), pch = c(rep(16, 4), rep(17, 3)),
xlim = c(0, 5), ylim = c(0, 5))
plot(X, col = c(rep("red", 4), rep("blue", 4)),
xlim = c(0, 5), ylim = c(0, 5))
X = matrix(c(3, 4, 2, 2, 4, 4, 1, 4, 2, 1, 4, 3, 4, 1),nrow = 7, byrow = T)
y = c(1, 1, 1, 1, 0, 0, 0)
plot(X, col = c(rep("red", 4), rep("blue", 4)), xlim = c(0, 5), ylim = c(0, 5))
plot(X, col = c(rep("red", 4), rep("blue", 3)), xlim = c(0, 5), ylim = c(0, 5))
abline(-0.5, 1)
c(1, 2, 2) %*% beta / sqrt(t(beta[2:3]) %*% beta[2:3])
beta = c(-intercept, solve(matrix(c(2, 1.5, 4, 3.5), nrow = 2, byrow = T), c(intercept, intercept)))
c(1, 2, 1.5) %*% beta
c(1, 4, 3.5) %*% beta
c(1, 2, 2) %*% beta / sqrt(t(beta[2:3]) %*% beta[2:3])
c(1, 4, 4) %*% beta / sqrt(t(beta[2:3]) %*% beta[2:3])
c(1, 2, 1) %*% beta / sqrt(t(beta[2:3]) %*% beta[2:3])
c(1, 4, 3) %*% beta / sqrt(t(beta[2:3]) %*% beta[2:3])
# part c
beta = c(-intercept, solve(matrix(c(2, 1.5, 4, 3.5), nrow = 2, byrow = T), c(intercept, intercept)))
c(1, 2, 1.5) %*% beta
c(1, 4, 3.5) %*% beta
c(1, 2, 2) %*% beta / sqrt(t(beta[2:3]) %*% beta[2:3])
c(1, 4, 4) %*% beta / sqrt(t(beta[2:3]) %*% beta[2:3])
c(1, 2, 1) %*% beta / sqrt(t(beta[2:3]) %*% beta[2:3])
c(1, 4, 3) %*% beta / sqrt(t(beta[2:3]) %*% beta[2:3])
# part c
beta = c(-(-0.5), solve(matrix(c(2, 1.5, 4, 3.5), nrow = 2, byrow = T), c(-0.5, -0.5)))
c(1, 2, 1.5) %*% beta
c(1, 4, 3.5) %*% beta
c(1, 2, 2) %*% beta / sqrt(t(beta[2:3]) %*% beta[2:3])
c(1, 4, 4) %*% beta / sqrt(t(beta[2:3]) %*% beta[2:3])
c(1, 2, 1) %*% beta / sqrt(t(beta[2:3]) %*% beta[2:3])
c(1, 4, 3) %*% beta / sqrt(t(beta[2:3]) %*% beta[2:3])
library(MASS)
eqscplot(X, col = c(rep("red", 4), rep("blue", 3)), xlim = c(0, 5), ylim = c(0, 5))
abline(-0.5, 1)
point = c(2,2)
lines(c(point[1], (beta[3] * ( beta[3] * point[1] - beta[2] * point[2]) - beta[1] * beta[2]) / (beta[2]^2 + beta[3]^2)),
c(point[2], (beta[2] * (-beta[3] * point[1] + beta[2] * point[2]) - beta[1] * beta[3]) / (beta[2]^2 + beta[3]^2)),
col = "red", lty = "solid")
point = c(4,4)
lines(c(point[1], (beta[3] * ( beta[3] * point[1] - beta[2] * point[2]) - beta[1] * beta[2]) / (beta[2]^2 + beta[3]^2)),
c(point[2], (beta[2] * (-beta[3] * point[1] + beta[2] * point[2]) - beta[1] * beta[3]) / (beta[2]^2 + beta[3]^2)),
col = "red", lty = "solid")
point = c(2,1)
lines(c(point[1], (beta[3] * ( beta[3] * point[1] - beta[2] * point[2]) - beta[1] * beta[2]) / (beta[2]^2 + beta[3]^2)),
c(point[2], (beta[2] * (-beta[3] * point[1] + beta[2] * point[2]) - beta[1] * beta[3]) / (beta[2]^2 + beta[3]^2)),
col = "blue", lty = "solid")
point = c(4,3)
lines(c(point[1], (beta[3] * ( beta[3] * point[1] - beta[2] * point[2]) - beta[1] * beta[2]) / (beta[2]^2 + beta[3]^2)),
c(point[2], (beta[2] * (-beta[3] * point[1] + beta[2] * point[2]) - beta[1] * beta[3]) / (beta[2]^2 + beta[3]^2)),
col = "blue", lty = "solid")
plot(X, col = c(rep("red", 4), rep("blue", 3)))
abline(intercept, slope)
points(c(2, 4), c(2, 4), pch = 8, col = "red")
points(c(2, 4), c(1, 3), pch = 8, col = "blue")
plot(X, col = c(rep("red", 4), rep("blue", 3)))
abline(intercept, slope)
points(c(2, 4), c(2, 4), pch = 3, col = "red")
points(c(2, 4), c(1, 3), pch = 3, col = "blue")
plot(X, col = c(rep("red", 4), rep("blue", 3)))
abline(intercept, slope)
points(c(2, 4), c(2, 4), pch = 2, col = "red")
points(c(2, 4), c(1, 3), pch = 2, col = "blue")
plot(X, col = c(rep("red", 4), rep("blue", 3)))
abline(intercept, slope)
points(c(2, 4), c(2, 4), pch = 1, col = "red")
points(c(2, 4), c(1, 3), pch = 1, col = "blue")
plot(X, col = c(rep("red", 4), rep("blue", 3)))
abline(intercept, slope)
points(c(2, 4), c(2, 4), pch = 5, col = "red")
points(c(2, 4), c(1, 3), pch = 5, col = "blue")
# part e
plot(X, col = c(rep("red", 4), rep("blue", 3)))
abline(intercept, slope)
points(c(2, 4), c(2, 4), pch = 6, col = "red")
points(c(2, 4), c(1, 3), pch = 6, col = "blue")
# part e
plot(X, col = c(rep("red", 4), rep("blue", 3)))
abline(intercept, slope)
points(c(2, 4), c(2, 4), pch = 7, col = "red")
points(c(2, 4), c(1, 3), pch = 7, col = "blue")
plot(X, col = c(rep("red", 4), rep("blue", 3)))
abline(-0.5, 1)
points(c(2, 4), c(2, 4), pch = 7, col = "red")
points(c(2, 4), c(1, 3), pch = 7, col = "blue")
abline(-1.25, 1.25, lty = "dotted", col = "red")
plot(X, col = c(rep("red", 4), rep("blue", 3)))
abline(-0.5, 1)
points(c(2, 4), c(2, 4), pch = 7, col = "red")
points(c(2, 4), c(1, 3), pch = 7, col = "blue")
abline(-1.25, 1.25, lty = "dotted", col = "red")
points(4, 2, col = "red", pch = 14)
plot(NA, NA, type = "n", xlim = c(-6, 2), ylim = c(0,4), asp = 1, xlab = "X1", ylab = "X2")
symbols(c(-1), c(2), circles = c(2), add = TRUE, inches = FALSE)
text(c(-1.25), c(2), "< 4")
text(c(-5), c(2), "> 4")
library(ISLR)
fix(Hitters)
Hitters =na.omit(Hitters)
x=model.matrix(Salary∼.,Hitters )[,-1]
y=Hitters$Salary
library(glmnet)
grid=10^seq(10,-2, length =100)
ridge.mod=glmnet (x,y,alpha=0, lambda=grid)
dim(coef(ridge.mod))
ridge.mod$lambda [50]
coef(ridge.mod)[ ,50]
ridge.mod$lambda [60]
coef(ridge.mod)[ ,60]
sqrt(sum(coef(ridge.mod)[-1,60]^2) )
predict (ridge.mod ,s=50,type="coefficients") [1:20,]
set.seed(1)
train=sample (1: nrow(x), nrow(x)/2)
test=(-train)
y.test=y[test]
ridge.mod=glmnet(x[train ,],y[ train],alpha=0,
lambda =grid ,thresh =1e-12)
ridge.pred=predict (ridge.mod ,s=4, newx=x[test ,])
mean((ridge.pred -y.test)^2)
mean((mean(y[train])-y.test)^2)
ridge.pred=predict (ridge.mod ,s=1e10 ,newx=x[test
,])
mean((ridge.pred -y.test)^2)
ridge.pred=predict (ridge.mod ,s=0, newx=x[test
,], exact=T)
mean((ridge.pred -y.test)^2)
lm(y∼x, subset=train)
predict (ridge.mod ,s=0,exact=T,type="
coefficients")[1:20,]
set.seed(1)
cv.out=cv.glmnet(x[train ,],y[ train],alpha=0)
plot(cv.out)
library(ISLR)
attach(Hitters)
Hitters =na.omit(Hitters)
x=model.matrix(Salary~.,Hitters )[,-1]
y=Salary
library(glmnet)
grid=10^seq(10,-2, length =100)
ridge.mod=glmnet (x,y,alpha=0, lambda=grid)
dim(coef(ridge.mod))
ridge.mod$lambda[50]
coef(ridge.mod)[,50]
ridge.mod$lambda[60]
coef(ridge.mod)[,60]
sqrt(sum(coef(ridge.mod)[-1,60]^2))
predict (ridge.mod ,s=50,type="coefficients") [1:20,]
set.seed(1)
train=sample (1: nrow(x), nrow(x)/2)
test=(-train)
y.test=y[test]
ridge.mod=glmnet(x[train ,],y[ train],alpha=0,lambda =grid ,thresh =1e-12)
ridge.pred=predict (ridge.mod ,s=4, newx=x[test ,])
mean((ridge.pred -y.test)^2)
mean((mean(y[train])-y.test)^2)
ridge.pred=predict (ridge.mod ,s=1e10 ,newx=x[test,])
mean((ridge.pred -y.test)^2)
ridge.pred=predict (ridge.mod ,s=0, newx=x[test,], exact=T)
mean((ridge.pred -y.test)^2)
lm(y~x, subset=train)
predict (ridge.mod ,s=0,exact=T,type="coefficients")[1:20,]
set.seed(1)
cv.out=cv.glmnet(x[train ,],y[ train],alpha=0)
plot(cv.out)
lasso.mod=glmnet(x[train ,],y[ train],alpha=1, lambda=grid)
plot(lasso.mod)
set.seed(1)
cv.out=cv.glmnet(x[train ,],y[ train],alpha=1)
plot(cv.out)
bestlam =cv.out$lambda.min
lasso.pred=predict (lasso.mod ,s=bestlam,newx=x[test ,])
mean((lasso.pred -y.test)^2)
out=glmnet (x,y,alpha=1, lambda=grid)
lasso.coef=predict (out ,type="
coefficients",s= bestlam) [1:20,]
lasso.coef
bestlam =cv.out$lambda.min
lasso.pred=predict (lasso.mod ,s=bestlam,newx=x[test ,])
mean((lasso.pred -y.test)^2)
out=glmnet (x,y,alpha=1, lambda=grid)
lasso.coef=predict (out ,type="coefficients",s= bestlam) [1:20,]
lasso.coef
set.seed(1)
x=matrix(rnorm (20*2), ncol=2)
y=c(rep(-1,10), rep(1,10))
x[y==1,]=x[y==1,] + 1
plot(x, col=(3-y))
dat=data.frame(x=x, y=as.factor(y))
library(e1071)
svmfit=svm(y∼., data=dat , kernel ="linear",cost=10,scale=FALSE)
plot(svmfit , dat)
dat=data.frame(x=x, y=as.factor(y))
library(e1071)
svmfit=svm(y~., data=dat , kernel ="linear",cost=10,scale=FALSE)
plot(svmfit , dat)
install.packages("e1071")
library(e1071)
dat=data.frame(x=x, y=as.factor(y))
library(e1071)
svmfit=svm(y~., data=dat , kernel ="linear",cost=10,scale=FALSE)
plot(svmfit , dat)
svmfit$index
summary(svmfit)
svmfit=svm(y~., data=dat , kernel ="linear", cost=0.1,scale=FALSE)
plot(svmfit , dat)
svmfit$index
summary(svmfit)
svmfit=svm(y~., data=dat , kernel ="linear", cost=0.1,scale=FALSE)
plot(svmfit , dat)
set.seed(1)
tune.out=tune(svm ,y~.,data=dat ,kernel="linear",ranges=list(cost=c(0.001,0.01, 0.1, 1,5,10,100) ))
summary (tune.out)
bestmod=tune.out$best.model
summary(bestmod)
xtest=matrix(rnorm (20*2) , ncol=2)
ytest=sample (c(-1,1), 20, rep=TRUE)
xtest[ytest==1,]= xtest[ytest==1,] + 1
testdat=data.frame(x=xtest ,y=as.factor(ytest))
ypred=predict (bestmod ,testdat)
table(predict =ypred , truth=testdat$y )
svmfit=svm(y∼., data=dat , kernel ="linear",cost =.01,scale=FALSE)
ypred=predict (svmfit ,testdat )
table(predict =ypred , truth=testdat$y )
x[y==1,]=x[y==1,]+0.5
plot(x, col=(y+5)/2, pch =19)
dat=data.frame(x=x,y=as.factor(y))
svmfit=svm(y~., data=dat , kernel ="linear",cost=1e5)
summary(svmfit)
plot(svmfit , dat)
svmfit=svm(y~., data=dat , kernel ="linear", cost=1)
summary(svmfit)
plot(svmfit ,dat)
set.seed(1)
x=matrix(rnorm (200*2) , ncol=2)
x[1:100,]=x[1:100,]+2
x[101:150 ,]=x[101:150,]-2
y=c(rep(1,150) ,rep(2,50))
dat=data.frame(x=x,y=as.factor(y))
plot(x, col=y)
train=sample (200,100)
svmfit=svm(y∼., data=dat[train ,], kernel ="radial",gamma=1,cost=1)
plot(svmfit , dat[train ,])
train=sample (200,100)
svmfit=svm(y~., data=dat[train ,], kernel ="radial",gamma=1,cost=1)
plot(svmfit , dat[train ,])
svmfit=svm(y~., data=dat[train ,], kernel="radial",gamma=1,cost=1e5)
plot(svmfit ,dat[train ,])
set.seed(1)
tune.out=tune(svm , y`., data=dat[train ,],kernel ="radial",
ranges=list(cost=c(0.1,1,10,100,1000),
gamma=c(0.5,1,2,3,4) ))
summary (tune.out)
table(true=dat[-train ,"y"], pred=predict(tune.out$best.model,newdata =dat[-train ,]))
)
)
))
library(ROCR)
rocplot =function (pred , truth , ...){
predob = prediction (pred , truth)
perf = performance (predob , "tpr", "fpr")
plot(perf ,...)}
svmfit.opt=svm(y∼., data=dat[train ,], kernel="radial",gamma=2, cost=1,
decision.values =T)
fitted =attributes (predict (svmfit.opt,dat[train ,],
decision.values=TRUE))$decision.values
par(mfrow=c(1,2))
rocplot (fitted ,dat[train ,"y"],main="Training Data")
library(ROCR)
rocplot =function (pred , truth , ...){
predob = prediction (pred , truth)
perf = performance (predob , "tpr", "fpr")
plot(perf ,...)}
svmfit.opt=svm(y~., data=dat[train ,], kernel="radial",gamma=2, cost=1,
decision.values =T)
fitted =attributes (predict (svmfit.opt,dat[train ,],
decision.values=TRUE))$decision.values
par(mfrow=c(1,2))
rocplot (fitted ,dat[train ,"y"],main="Training Data")
library(ROCR)
install.packages("ROCR")
library(ROCR)
rocplot =function (pred , truth , ...){
predob = prediction (pred , truth)
perf = performance (predob , "tpr", "fpr")
plot(perf ,...)}
svmfit.opt=svm(y~., data=dat[train ,], kernel="radial",gamma=2, cost=1,
decision.values =T)
fitted =attributes (predict (svmfit.opt,dat[train ,],
decision.values=TRUE))$decision.values
par(mfrow=c(1,2))
rocplot (fitted ,dat[train ,"y"],main="Training Data")
library(ROCR)
rocplot =function (pred , truth , ...){
predob = prediction (pred , truth)
perf = performance (predob , "tpr", "fpr")
plot(perf ,...)}
svmfit.opt=svm(y~., data=dat[train ,], kernel="radial",gamma=2, cost=1,
decision.values =T)
fitted =attributes (predict (svmfit.opt,dat[train ,],
decision.values=TRUE))$decision.values
par(mfrow=c(1,2))
rocplot (fitted ,dat[train ,"y"],main="Training Data")
svmfit.flex=svm(y~., data=dat[train ,],kernel ="radial",gamma=50, cost=1,
decision.values =T)
fitted=attributes (predict (svmfit.flex,dat[train ,],
decision.values=T))$decision.values
rocplot (fitted ,dat[train,"y"],add=T,col="red ")
fitted =attributes (predict (svmfit.opt,dat[-train ,],
decision.values=T))$decision.values
rocplot (fitted ,dat[-train ,"y"], main="Test Data")
fitted=attributes (predict (svmfit.flex,dat[- train ,],
decision.values=T))$decision.values
rocplot (fitted ,dat[-train,"y"],add=T,col="red")
set.seed(1)
x=rbind(x, matrix(rnorm (50*2) , ncol=2))
y=c(y, rep(0,50))
x[y==0,2]= x[y==0 ,2]+2
dat=data.frame(x=x, y=as.factor(y))
par(mfrow=c(1,1))
plot(x,col=(y+1))
svmfit=svm(y∼., data=dat , kernel ="radial", cost=10,gamma =1)
plot(svmfit , dat)
svmfit=svm(y~., data=dat , kernel ="radial", cost=10,gamma =1)
plot(svmfit , dat)
library(ISLR)
names(Khan)
dim(Khan$xtrain )
dim(Khan$xtest )
length(Khan$ytrain )
length(Khan$ytest )
table(Khan$ytrain )
table(Khan$ytest )
dat=data.frame(x=Khan$xtrain ,
y=as.factor(Khan$ytrain ))
out=svm(y∼., data=dat , kernel
="linear",cost=10)
summary (out)
table(out$fitted , dat$y)
dat.te=data.frame(x=Khan$xtest ,
y=as.factor(Khan$ytest ))
pred.te=predict (out , newdata =dat.te)
table(pred.te, dat.te$y)
library(ISLR)
Boston?
?Boston
Boston
library(MASS)
?Boston
dim(Boston)
dim(Auto)
rm(glm.fit)
rm(list = ls())
ls
?ls()
2016wr = read.csv("2016 Fantasy Stats WR only.csv")
wr2016 = read.csv("2016 Fantasy Stats WR only.csv")
setwd("~/Documents/Python/nflfantasypredictor/datasets/WR")
wr2016 = read.csv("2016 Fantasy Stats WR only.csv")
names(wr2016)
attach(wr2016)
PPR
View(TD)
View(Yds)
plot(Yds)
